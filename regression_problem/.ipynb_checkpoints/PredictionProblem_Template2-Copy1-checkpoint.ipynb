{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5dbbea0e-3a99-459e-abd6-0959e6946869",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem\"\n",
    "subtitle: \"STAT 303-3 Spring 25\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: show\n",
    "    embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7523b-6099-4001-a997-60005980e73a",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "- Put the parts of your code under the corresponding sections. (0.25/2 points will be taken off for not doing this.)\n",
    "- Do not include any redundant/irrelevant code, text or comments. (0.5/2 points will be taken off for not doing this.)\n",
    "- **Your code must run without any errors or runtime issues.** (Failure to meet this condition will result in a 0.)\n",
    "- **Your code must return your Public Leaderboard score.** (Failure to meet this condition will result in a 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03031cca-1a24-4e66-926e-2b32f85f3cc7",
   "metadata": {},
   "source": [
    "## 1) Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65f439-927b-4b40-9008-a715356fbe58",
   "metadata": {},
   "source": [
    "Put all the Python libraries and tools you imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb866b1-8f62-4ca4-a39e-5774486da357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, impute\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error # mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877d116-1e8d-426e-84ba-10c47e28a1ac",
   "metadata": {},
   "source": [
    "## 2) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177363af-51a7-4b16-b6d2-33ba5796bd20",
   "metadata": {},
   "source": [
    "- This section is required to include the code that reads, cleans and preprocesses the datasets.\n",
    "- Note that both the training and test datasets should undergo the same sequence of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcc4a5b-777a-4b75-8fd7-b0594591ea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                int64\n",
       "listing_location                                 object\n",
       "description                                      object\n",
       "host_since                                       object\n",
       "host_location                                    object\n",
       "host_about                                       object\n",
       "host_response_time                               object\n",
       "host_response_rate                               object\n",
       "host_acceptance_rate                             object\n",
       "host_neighbourhood                               object\n",
       "host_listings_count                             float64\n",
       "host_total_listings_count                       float64\n",
       "host_verifications                               object\n",
       "host_has_profile_pic                             object\n",
       "host_identity_verified                           object\n",
       "neighbourhood_cleansed                           object\n",
       "latitude                                        float64\n",
       "longitude                                       float64\n",
       "property_type                                    object\n",
       "room_type                                        object\n",
       "accommodates                                      int64\n",
       "bathrooms_text                                   object\n",
       "bedrooms                                        float64\n",
       "beds                                            float64\n",
       "amenities                                        object\n",
       "price                                            object\n",
       "minimum_nights                                    int64\n",
       "maximum_nights                                    int64\n",
       "minimum_minimum_nights                            int64\n",
       "maximum_minimum_nights                            int64\n",
       "minimum_maximum_nights                            int64\n",
       "maximum_maximum_nights                            int64\n",
       "minimum_nights_avg_ntm                          float64\n",
       "maximum_nights_avg_ntm                          float64\n",
       "has_availability                                 object\n",
       "availability_30                                   int64\n",
       "availability_60                                   int64\n",
       "availability_90                                   int64\n",
       "availability_365                                  int64\n",
       "number_of_reviews                                 int64\n",
       "number_of_reviews_ltm                             int64\n",
       "number_of_reviews_l30d                            int64\n",
       "first_review                                     object\n",
       "last_review                                      object\n",
       "review_scores_rating                            float64\n",
       "review_scores_accuracy                          float64\n",
       "review_scores_cleanliness                       float64\n",
       "review_scores_checkin                           float64\n",
       "review_scores_communication                     float64\n",
       "review_scores_location                          float64\n",
       "review_scores_value                             float64\n",
       "instant_bookable                                   bool\n",
       "calculated_host_listings_count                    int64\n",
       "calculated_host_listings_count_entire_homes       int64\n",
       "calculated_host_listings_count_private_rooms      int64\n",
       "calculated_host_listings_count_shared_rooms       int64\n",
       "reviews_per_month                               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ccd4d-ed90-4683-b818-01786b379fcc",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "1. drop unecessary cols - same in both\n",
    "   1. VIF cols, room_type, \n",
    "3. clean messy cols -- bathrooms_test, true/false to 1/0\n",
    "   1. bathrooms_text, host_identity_verified, property_type\n",
    "   2. description - luxury words\n",
    "4. OHE\n",
    "5. impute\n",
    "6. scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fdb0dc-9be1-49c6-a9a9-6cf90adadb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many cols determined as multicollinear with VIF vals above 8\n",
    "    # others just unecessary, too messy, too many categories, etc.\n",
    "\n",
    "\n",
    "cols_to_drop = ['has_availability', 'host_verifications', 'host_response_time',\n",
    "                'host_since', 'host_location', 'host_neighbourhood', 'host_has_profile_pic',\n",
    "                'neighbourhood_cleansed', 'first_review', 'last_review', 'room_type',\n",
    "                'amenities', 'host_about','minimum_minimum_nights', 'minimum_maximum_nights',\n",
    "                'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm',\n",
    "                'availability_30', 'availability_60', 'availability_90', 'calculated_host_listings_count']\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5f7c07-f3a4-4dd3-b6f8-2da73ed005c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean $ and % from numeric cols\n",
    "\n",
    "def clean_cols(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.replace('$', '').replace('%', '').replace(',', '')\n",
    "    return float(val)\n",
    "\n",
    "train[['price','host_acceptance_rate','host_response_rate']] = train[['price','host_acceptance_rate','host_response_rate']].map(clean_cols)\n",
    "test[['host_acceptance_rate','host_response_rate']] = test[['host_acceptance_rate','host_response_rate']].map(clean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9fa0ae-caff-4670-85a4-f8dfde5fa190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean bathrooms_text - convert half-bath to 0.5\n",
    "train['bathrooms_text'] = train['bathrooms_text'].replace('Half-bath', '0.5')\n",
    "test['bathrooms_text'] = test['bathrooms_text'].replace('Half-bath', '0.5')\n",
    "\n",
    "# extract numeric part\n",
    "train['bathrooms_text'] = train['bathrooms_text'].str.extract(r'(\\d+\\.?\\d*)')[0].astype(float)\n",
    "test['bathrooms_text'] = test['bathrooms_text'].str.extract(r'(\\d+\\.?\\d*)')[0].astype(float)\n",
    "\n",
    "test = test.rename(columns={'bathrooms_text': 'bathrooms'})\n",
    "train = train.rename(columns={'bathrooms_text': 'bathrooms'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77019f6a-675f-4827-9164-b1f99aeb2052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/yd_rkzv93459x04g3jzsjwcr0000gn/T/ipykernel_52490/1847232823.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['host_identity_verified'] = train['host_identity_verified'].fillna(False).astype(int)\n",
      "/var/folders/yg/yd_rkzv93459x04g3jzsjwcr0000gn/T/ipykernel_52490/1847232823.py:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['host_identity_verified'] = test['host_identity_verified'].fillna(False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# host identity verified - convert to 0/1\n",
    "# instant bookable - convert to 0/1\n",
    "\n",
    "train['instant_bookable'] = train['instant_bookable'].fillna(False).astype(int)\n",
    "test['instant_bookable'] = test['instant_bookable'].fillna(False).astype(int)\n",
    "\n",
    "train['host_identity_verified'] = train['host_identity_verified'].fillna(False).astype(int)\n",
    "test['host_identity_verified'] = test['host_identity_verified'].fillna(False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4102b6d4-775b-410e-ad23-d0448a2ab4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# property type -- make new col, 1 if entire property and 0 otherwise\n",
    "\n",
    "train['is_entire_place'] = train['property_type'].str.contains('entire', case=False, na=False).astype(int)\n",
    "test['is_entire_place'] = test['property_type'].str.contains('entire', case=False, na=False).astype(int)\n",
    "\n",
    "train = train.drop('property_type', axis=1)\n",
    "test = test.drop('property_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb8face1-ea3c-466e-a7ad-242579a12c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description -- make new col, 1 if contains 'luxury' words\n",
    "\n",
    "keywords = ['luxury', 'luxurious', 'penthouse', 'exclusive', 'elegant',\n",
    "            'premium', 'high-end', 'designer', 'upscale', 'chic',\n",
    "            'modern', 'deluxe', 'sophisticated', 'breathtaking','custom-built', 'architect-designed',\n",
    "            'state-of-the-art','prestigious', 'top-tier', '5-star', 'five-star']\n",
    "\n",
    "pattern = '|'.join(keywords)\n",
    "train['luxury_description'] = train['description'].str.contains(pattern, case=False, na=False).astype(int)\n",
    "test['luxury_description'] = test['description'].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "train = train.drop('description', axis=1)\n",
    "test = test.drop('description', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1aed1a7-fb88-4ef8-8156-c8576ec361dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE location\n",
    "\n",
    "location_dummies = pd.get_dummies(train['listing_location'], prefix='location', drop_first=True)\n",
    "train = pd.concat([train, location_dummies], axis=1).drop('listing_location', axis=1)\n",
    "\n",
    "location_dummies = pd.get_dummies(test['listing_location'], prefix='location', drop_first=True)\n",
    "test = pd.concat([test, location_dummies], axis=1).drop('listing_location', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7e7b994-6ef7-46f7-a598-440132aa1a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['location_chicago', 'location_kauai']] = train[['location_chicago', 'location_kauai']].astype(int)\n",
    "test[['location_chicago', 'location_kauai']] = test[['location_chicago', 'location_kauai']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69e2928d-ba7f-4555-ab32-a5be880768c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                 0\n",
       "host_response_rate                               557\n",
       "host_acceptance_rate                             331\n",
       "host_listings_count                                3\n",
       "host_total_listings_count                          3\n",
       "host_identity_verified                             0\n",
       "latitude                                           0\n",
       "longitude                                          0\n",
       "accommodates                                       0\n",
       "bathrooms                                          3\n",
       "bedrooms                                          23\n",
       "beds                                              10\n",
       "price                                              0\n",
       "minimum_nights                                     0\n",
       "maximum_nights                                     0\n",
       "maximum_minimum_nights                             0\n",
       "availability_365                                   0\n",
       "number_of_reviews                                  0\n",
       "number_of_reviews_ltm                              0\n",
       "number_of_reviews_l30d                             0\n",
       "review_scores_rating                            1810\n",
       "review_scores_accuracy                          1810\n",
       "review_scores_cleanliness                       1810\n",
       "review_scores_checkin                           1810\n",
       "review_scores_communication                     1810\n",
       "review_scores_location                          1810\n",
       "review_scores_value                             1810\n",
       "instant_bookable                                   0\n",
       "calculated_host_listings_count_entire_homes        0\n",
       "calculated_host_listings_count_private_rooms       0\n",
       "calculated_host_listings_count_shared_rooms        0\n",
       "reviews_per_month                               1810\n",
       "is_entire_place                                    0\n",
       "luxury_description                                 0\n",
       "location_chicago                                   0\n",
       "location_kauai                                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6526742f-041a-4995-a48a-13874f612043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE MISSING VALS\n",
    "\n",
    "# fit to train data, transform train and test data\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "train_impute_cols = [col for col in train.columns if col not in ['id', 'price']]\n",
    "\n",
    "#scale\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_array = scaler.fit_transform(train[train_impute_cols])\n",
    "scaled_train_df = pd.DataFrame(scaled_train_array, columns=train_impute_cols, index=train.index)\n",
    "\n",
    "train_imputed_arr = imputer.fit_transform(scaled_train_df) # first scale\n",
    "train_unscaled_data = scaler.inverse_transform(train_imputed_arr) # then undo scale\n",
    "\n",
    "train_imputed = train.copy()\n",
    "train_imputed[train_impute_cols] = pd.DataFrame(train_unscaled_data, columns=train_impute_cols, index=train.index)\n",
    "\n",
    "\n",
    "# test - use same scale\n",
    "test_impute_cols = [col for col in test.columns if col != 'id']\n",
    "\n",
    "\n",
    "scaled_test_array = scaler.transform(test[test_impute_cols])\n",
    "scaled_test_df = pd.DataFrame(scaled_test_array, columns=test_impute_cols, index=test.index)\n",
    "\n",
    "test_imputed_arr = imputer.transform(scaled_test_df)\n",
    "test_unscaled_data = scaler.inverse_transform(test_imputed_arr)\n",
    "\n",
    "test_imputed = test.copy()\n",
    "test_imputed[test_impute_cols] = pd.DataFrame(test_unscaled_data, columns = test_impute_cols, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be4968d-7176-4e43-b26a-94a52898f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice predictors - no id !! but save for predictions\n",
    "\n",
    "X_train = train_imputed.drop(columns=['price','id'])\n",
    "y_train = np.log(train_imputed['price'])\n",
    "\n",
    "X_test = test_imputed.drop(columns=['id'])\n",
    "test_ids = test_imputed['id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1071eae2-9655-4074-a7c8-9ec5ed96ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078e4fa-9a22-44ca-b1e3-944f25dac70a",
   "metadata": {},
   "source": [
    "## 3) Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5c8b4-9aab-4022-8561-5f8bf964cab3",
   "metadata": {},
   "source": [
    "- This section is required to train the **already tuned** model and obtain the test predictions (or prediction probabilities) with it.\n",
    "- As written in the instructions, your code must not have any runtime issues, so **do NOT include your grid search here!** You will still need to tune your model to pass the thresholds. However, you need to keep that as your personal work and should NOT include the grid search here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "80ccfd51-090e-4685-a4fc-d26c8fbe12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = Ridge(alpha = 0.005)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = np.exp(model.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({'id': test_ids,'predicted': y_pred})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "15966496-e9cf-40fb-9359-2f33d6e5ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best avg cv performance: 0.3936951100339348\n",
      "Best hyperparam: 440.2441790821732\n"
     ]
    }
   ],
   "source": [
    "# create an array of hyperparameter values\n",
    "alphas = 10**np.linspace(10,-2,200)*0.5 # 200 alpha values\n",
    "\n",
    "# create an empty list\n",
    "cv_scores = []\n",
    "\n",
    "# now, we will use ridge, lasso and cross_val_score\n",
    "for alpha in alphas: # for each hyperparam\n",
    "    model = Ridge(alpha=alpha) # create a model with that that hyperparam\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_train, scoring = 'neg_mean_absolute_error')\n",
    "    cv_scores.append(cv_score)\n",
    "\n",
    "avg_cv_results = -np.array(cv_scores).mean(axis=1)\n",
    "\n",
    "# first, find the best score: lowest MAE\n",
    "print('Best avg cv performance:', np.min(avg_cv_results))\n",
    "print('Best hyperparam:', alphas[np.argmin(avg_cv_results)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Ridge(alpha = alphas[np.argmin(avg_cv_results)])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_preds = np.exp(model.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,           # original id column from the test data\n",
    "    'predicted': y_preds         # your model’s predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('sub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5014cdad-1519-4c00-a5b8-c35fdf9ad35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price error value: 45.031844341816175\n",
      "Best alpha: 0.005\n"
     ]
    }
   ],
   "source": [
    "alphas = 10**np.linspace(10,-2,200)*0.5\n",
    "cv_preds = []\n",
    "\n",
    "for alpha in alphas: # for each alpha\n",
    "    model = Ridge(alpha=alpha) # create model with that alpha\n",
    "    cv_pred = cross_val_predict(model, X_train_scaled, y_train) #no scoring because the output will be the preds, not performances\n",
    "\n",
    "    cv_preds.append(cv_pred)\n",
    "\n",
    "# each row: the prediction for each obs in the training data WHEN that obs was iin the assessment fold\n",
    "\n",
    "# convert the log predictions into the linear scale \n",
    "cv_pred_errors = np.exp(np.array(cv_preds)) - np.array(np.exp(y_train))\n",
    "\n",
    "# calculate MAE for each alpha\n",
    "cv_maes = np.abs((cv_pred_errors).mean(axis=1))\n",
    "\n",
    "print('Price error value:', np.min(cv_maes))\n",
    "print('Best alpha:', alphas[np.argmin(cv_maes)]) # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0f2125dc-e91e-4182-8b79-099047328076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best avg cv performance: 0.38836468890107834\n",
      "Best hyperparam: 0.011502150598864608\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "\n",
    "\n",
    "# create an array of hyperparameter values\n",
    "alphas = 10**np.linspace(10,-2,200)*0.5 # 200 alpha values\n",
    "\n",
    "# create an empty list\n",
    "cv_scores = []\n",
    "\n",
    "# now, we will use ridge, lasso and cross_val_score\n",
    "for alpha in alphas: # for each hyperparam\n",
    "    model = Lasso(alpha=alpha) # create a model with that that hyperparam\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_train, scoring = 'neg_mean_absolute_error')\n",
    "    cv_scores.append(cv_score)\n",
    "\n",
    "avg_cv_results = -np.array(cv_scores).mean(axis=1)\n",
    "\n",
    "# first, find the best score: lowest MAE\n",
    "print('Best avg cv performance:', np.min(avg_cv_results))\n",
    "print('Best hyperparam:', alphas[np.argmin(avg_cv_results)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Ridge(alpha = alphas[np.argmin(avg_cv_results)])\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_preds = np.exp(model.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,           # original id column from the test data\n",
    "    'predicted': y_preds         # your model’s predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "edcaa4d4-4960-43a9-ac4d-7032793e087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors = 5, weights = 'distance')\n",
    "\n",
    "# train\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(knn_model.predict(X_test_scaled))\n",
    "\n",
    "#y_pred_train = knn_model.predict(X_train_scaled)\n",
    "#print(mean_absolute_error(y_train, y_pred_train))\n",
    "\n",
    "# evaluate\n",
    "#print(root_mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('knn1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4f5a0476-afdf-4310-bef1-2c3319d68800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model 2\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors = 6, weights = 'distance')\n",
    "\n",
    "# train\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(knn_model.predict(X_test_scaled))\n",
    "\n",
    "#y_pred_train = knn_model.predict(X_train_scaled)\n",
    "#print(mean_absolute_error(y_train, y_pred_train))\n",
    "\n",
    "# evaluate\n",
    "#print(root_mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('knn3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "db45145c-1ada-4077-a0cb-5db22297c1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.006491575585352442\n",
      "2 0.005611904898415031\n",
      "3 0.005545588882155145\n",
      "4 0.005104618310302251\n",
      "5 0.00505232653268439\n",
      "6 0.0051739539253849165\n",
      "7 0.005197984986656579\n",
      "8 0.005096219877715136\n",
      "9 0.005051749273379211\n",
      "10 0.005023153359506428\n",
      "11 0.005033191619682778\n",
      "12 0.0050634266116792075\n",
      "13 0.005107170894904329\n",
      "14 0.005029630292161799\n",
      "15 0.005033615855686972\n",
      "16 0.005024790510806664\n",
      "17 0.005014891466792658\n",
      "18 0.0050199232593925525\n",
      "19 0.005018959100357977\n"
     ]
    }
   ],
   "source": [
    "# CV KNN\n",
    "\n",
    "for i in range(1,20):\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=i, weights='distance')\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    #y_preds = np.exp(knn_model.predict(X_test_scaled))\n",
    "    y_pred_train = knn_model.predict(X_train_scaled)\n",
    "    print(i, mean_absolute_error(y_train, y_pred_train))\n",
    "\n",
    "    #sub = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b94e90a3-2f54-4240-941e-4e02825e5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model 3\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors = 17, weights = 'distance')\n",
    "\n",
    "# train\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(knn_model.predict(X_test_scaled))\n",
    "\n",
    "#y_pred_train = knn_model.predict(X_train_scaled)\n",
    "#print(mean_absolute_error(y_train, y_pred_train))\n",
    "\n",
    "# evaluate\n",
    "#print(root_mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('knn4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79fbfdd6-cf1c-43e5-8d7f-6aaf53eb8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH CV\n",
    "\n",
    "model = KNeighborsRegressor() # Any object input that will be fixed (not tuned) can be inputted.\n",
    "\n",
    "# Second, create a hyperparam grid.\n",
    "grid = {'n_neighbors':np.arange(10,160,10), 'weights':['uniform', 'distance']}\n",
    "\n",
    "# Create the grid search\n",
    "gscv = GridSearchCV(model, grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "gscv.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(gscv.best_estimator_.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('gscv1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35eb866a-8b36-4ba7-bff2-b6f944c8c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch unscaled idk\n",
    "\n",
    "model = KNeighborsRegressor() # Any object input that will be fixed (not tuned) can be inputted.\n",
    "\n",
    "# Second, create a hyperparam grid.\n",
    "grid = {'n_neighbors':np.arange(10,160,10), 'weights':['uniform', 'distance']}\n",
    "\n",
    "# Create the grid search\n",
    "gscv = GridSearchCV(model, grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "gscv.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(gscv.best_estimator_.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('gscv2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb4d857-4648-4ba1-8650-6f708af85b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 2 done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m10\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     13\u001b[0m gscv \u001b[38;5;241m=\u001b[39m GridSearchCV(model, grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m gscv\u001b[38;5;241m.\u001b[39mfit(X_train_poly, y_train)\n\u001b[1;32m     17\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(gscv\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test_poly))\n\u001b[1;32m     19\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: test_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: y_preds})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:917\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    914\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    916\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 917\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m _score(\n\u001b[1;32m    918\u001b[0m     estimator, X_test, y_test, scorer, score_params_test, error_score\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:982\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[1;32m    980\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:253\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:345\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[1;32m    344\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[0;32m--> 345\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(\n\u001b[1;32m    346\u001b[0m     estimator, response_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, X, pos_label\u001b[38;5;241m=\u001b[39mpos_label\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:87\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 87\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[1;32m     88\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_response.py:238\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should either be a classifier to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused with response_method=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or the response_method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got a regressor with response_method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     prediction_method \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict\n\u001b[0;32m--> 238\u001b[0m     y_pred, pos_label \u001b[38;5;241m=\u001b[39m prediction_method(X), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_response_method_used:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, pos_label, prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_regression.py:245\u001b[0m, in \u001b[0;36mKNeighborsRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    243\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X)\n\u001b[1;32m    247\u001b[0m weights \u001b[38;5;241m=\u001b[39m _get_weights(neigh_dist, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\n\u001b[1;32m    249\u001b[0m _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_base.py:850\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    843\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    846\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    847\u001b[0m     )\n\u001b[1;32m    848\u001b[0m )\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 850\u001b[0m     results \u001b[38;5;241m=\u001b[39m ArgKmin\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    851\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    852\u001b[0m         Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[1;32m    853\u001b[0m         k\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[1;32m    854\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[1;32m    855\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_,\n\u001b[1;32m    856\u001b[0m         strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    857\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    862\u001b[0m ):\n\u001b[1;32m    863\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    864\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    865\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:278\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    279\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    280\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m    281\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    282\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m    283\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[1;32m    284\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39mmetric_kwargs,\n\u001b[1;32m    285\u001b[0m         strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    286\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    291\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    292\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    299\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:90\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/threadpoolctl.py:176\u001b[0m, in \u001b[0;36mthreadpool_limits.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munregister()\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munregister\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## poly features\n",
    "# GRIDSEARCH CV\n",
    "\n",
    "for i in range(2,10):\n",
    "    \n",
    "    X_train_poly = PolynomialFeatures(degree=i, include_bias=False).fit_transform(X_train_scaled)\n",
    "    X_test_poly = PolynomialFeatures(degree=i, include_bias=False).fit_transform(X_test_scaled)\n",
    "\n",
    "    model = KNeighborsRegressor()\n",
    "\n",
    "    grid = {'n_neighbors': np.arange(10,160,10), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "    gscv = GridSearchCV(model, grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    gscv.fit(X_train_poly, y_train)\n",
    "\n",
    "    y_preds = np.exp(gscv.best_estimator_.predict(X_test_poly))\n",
    "\n",
    "    submission = pd.DataFrame({'id': test_ids, 'predicted': y_preds})\n",
    "\n",
    "    submission.to_csv(f'poly_{i}_gscv.csv', index=False)\n",
    "    print('Degree', i, 'done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d6cf599-fb50-4054-8127-c67bd30179e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH CV again, diff scale\n",
    "\n",
    "model = KNeighborsRegressor() # Any object input that will be fixed (not tuned) can be inputted.\n",
    "\n",
    "# Second, create a hyperparam grid.\n",
    "grid = {'n_neighbors':np.arange(5,150,5), 'weights':['uniform', 'distance']}\n",
    "\n",
    "# Create the grid search\n",
    "gscv = GridSearchCV(model, grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "gscv.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(gscv.best_estimator_.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('gscv_4_22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b7c90d8-5e22-4b44-be79-09118e2fec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH CV again, diff scale\n",
    "\n",
    "model = KNeighborsRegressor() # Any object input that will be fixed (not tuned) can be inputted.\n",
    "\n",
    "# Second, create a hyperparam grid.\n",
    "grid = {'n_neighbors':np.arange(5,50,1), 'weights':['uniform', 'distance'], 'metric':['manhattan', 'euclidean']}\n",
    "\n",
    "# Create the grid search\n",
    "gscv = GridSearchCV(model, grid, scoring='neg_mean_absolute_error')\n",
    "\n",
    "gscv.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds = np.exp(gscv.best_estimator_.predict(X_test_scaled))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        \n",
    "    'predicted': y_preds   \n",
    "})\n",
    "\n",
    "submission.to_csv('gscv_4_22_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2d1c1-edd2-428c-9944-2bafc8f9291b",
   "metadata": {},
   "source": [
    "## 4) Exporting the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e92cdc-e3e0-423a-a248-cf3b1cf99f68",
   "metadata": {},
   "source": [
    "Include the code that (1) puts the predictions in the format that Kaggle understands and (2) exports it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29416a6-4ae8-4521-8842-c83b9b4097d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
